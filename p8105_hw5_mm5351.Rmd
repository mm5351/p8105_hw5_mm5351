---
title: "p8105_hw5_mm5351"
author: "Martha Mulugeta"
date: "11/6/2019"
output: github_document
---

**Problem 1**
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

set.seed(10)
```

```{r iris}
iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

iris_fill = function(x) {
  if (is.numeric(x)) {
    replace_na(x, mean(x, na.rm = TRUE))
  } else if (is.character(x)) {
    replace_na(x, "virginica")
  }
}

output = map_df(iris_with_missing, iris_fill) 
```

**Problem 2**
```{r study_df iteration}
study_df = tibble(
participant = list.files(path = "./Data", pattern = ".csv",  all.files = TRUE, full.names = TRUE)) %>% 
  mutate(data = map(participant, read_csv)) %>% 
  unnest() 
```

```{r study_df tidy}
study_df = 
  study_df %>%
  separate(col = participant, sep = "_", into = c("arm", "subjectID")) %>% 
  mutate(
    arm = str_replace(arm, "./Data/", ""),
    subjectID = str_replace(subjectID, ".csv", "")
  ) %>% 

 pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observation"
  ) %>%
  mutate(week = str_replace(week, "week_", "")) %>%
  unite(participant, arm, subjectID, sep = " ", remove = FALSE) %>% 
  group_by(week, participant) 
```

```{r plot1}
study_df %>%  
ggplot(aes(x = week, y = observation, color = participant, group = participant)) +
  geom_line() + 
     labs(
    title = "Observations Over Time",
    x = "Week",
    y = "Observation")
```
The above spaghetti plot depicts between group differences in observations over time. The control arm's observations are lower than the experimental arm's observations over time. Also, solely based on how the curves look, it appears as though the experimental arm's observations are increasing over time whereas the control arm's observations are remaining relatively stable over time. 

**Problem 3**
```{r regression}
sim_regression = function(n = 30, beta0 = 2, beta1 = 0) {
   sim_data = tibble(
    x = rnorm(n),
    y = beta0 + beta1 * x + rnorm(n, 0, sqrt(50))
  )
  
ls_fit = lm(y ~ x, data = sim_data) %>% 
  broom::tidy()
}
```

```{r regression iteration}
sim_results = 
  tibble(
    beta1 = c(0, 1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output_list = map(.x = beta1, ~rerun(10000, sim_regression(beta1 = .x))),
    output_df = map(output_list, bind_rows)
  ) %>% 
  select(-output_list) %>% 
  unnest(output_df) %>% 
  filter(term == "(Intercept)") %>% 
  select(beta1, estimate, p.value) 
```

```{r plot2}
reject_null = 
  sim_results %>% 
  count(beta1, estimate, p.value) %>% 
  mutate(total = sum(n)) %>% 
  filter(p.value < 0.05) %>% 
  count(beta1, estimate, p.value, total) %>% 
  group_by(beta1) %>% 
  mutate(total_rejectnull = sum(n), 
         proportion = ((total_rejectnull / total) * 100)) %>% 
  select(beta1, proportion)

reject_null %>% 
  ggplot(aes(x = beta1, y = proportion)) +
  geom_line(color = 'turquoise') +
  labs(
      title = "Proportion of Times Null was Rejected",
      x = "Beta1",
      y = "Proportion (%)")
```
The above plots represents the proportion of times the null was rejected for each of the seven beta1 values (0, 1, 2, 3, 4, 5, and 6). Based on the plot, we can see that the null was rejected between 4.38% and 4.55% of the time. Effect size and power have a positive linear relationship, such that as effect size increases, power increases. The y-axis of the above plot represents the power of the test, which is the probability that the test will find a statistically significant difference when one exists. Effect size, in contrast, not only indicates if a difference is statistically significant, but also if it is meaningful. Therefore, as power increases (correctly identified statistical significance), effect size increases(meaningful statistical significance).

```{r plot3}
mean_estimate = 
  sim_results %>% 
  group_by(beta1) %>% 
  summarize(mean_estimate = mean(estimate)) 

mean_rejectnull =
  sim_results %>% 
  filter(p.value < 0.05) %>% 
  group_by(beta1) %>% 
  summarize(mean_estimate = mean(estimate))

ggplot() +
  geom_line(data = mean_estimate, aes(x = beta1, y = mean_estimate), color = 'turquoise') +
  geom_line(data = mean_rejectnull, aes(x = beta1, y = mean_estimate), color = 'magenta') +
  xlab('True Beta1') +
  ylab('Average Estimate of Beta1')
```
In the above plot, the turquoise line representes the average estimate of beta1 and the magenta line represents the average estiamte of beta1 in samples where the null was rejected.
The sample average of estimated beta1 across tests for which the null is rejected is not approximately equal to the true value of beta1. This could be due to the random error depicted in our linear regression model as epsilon, which measures how far above and below the actual observations are from the true regression line (of which the slope is the true beta1 value).  





